{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gdown\n",
        "%cd {HOME}\n",
        "!gdown '1pz68D1Gsx80MoPg-_q-IbEdESEmyVLm-'"
      ],
      "metadata": {
        "id": "bkKyyyNxu5EC",
        "outputId": "235aff6a-76d9-43ed-c841-0f8871d6c54b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1pz68D1Gsx80MoPg-_q-IbEdESEmyVLm-\n",
            "To: /content/vehicle-counting.mp4\n",
            "100% 35.3M/35.3M [00:00<00:00, 165MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-NDa4l_JP8tz",
        "outputId": "ecadb34a-704f-4c91-b632-d594c2e15701"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.74 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Setup complete ‚úÖ (2 CPUs, 12.7 GB RAM, 33.6/78.2 GB disk)\n",
            "Collecting supervision\n",
            "  Downloading supervision-0.22.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from supervision) (0.7.1)\n",
            "Requirement already satisfied: matplotlib>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from supervision) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from supervision) (1.26.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.5.5.64 in /usr/local/lib/python3.10/dist-packages (from supervision) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=9.4 in /usr/local/lib/python3.10/dist-packages (from supervision) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.10/dist-packages (from supervision) (6.0.1)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from supervision) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6.0->supervision) (1.16.0)\n",
            "Downloading supervision-0.22.0-py3-none-any.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m135.7/135.7 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: supervision\n",
            "Successfully installed supervision-0.22.0\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "!pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()\n",
        "\n",
        "!pip install supervision\n",
        "import supervision as sv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "up4WumnRRAbx",
        "outputId": "76cc3f97-0d1a-4722-f753-0371ccfdb226"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x.pt to 'yolov8x.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 131M/131M [00:00<00:00, 412MB/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLOv8x summary (fused): 268 layers, 68,200,608 parameters, 0 gradients, 257.8 GFLOPs\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "model = YOLO(\"yolov8x.pt\")\n",
        "model.fuse()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kBUMY8PzRawS"
      },
      "outputs": [],
      "source": [
        "CLASS_NAMES_DICT = model.model.names\n",
        "\n",
        "selected_classes = [2,3,5,7]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "D8SMXpw9UTVg"
      },
      "outputs": [],
      "source": [
        "def box_anotator(frame, detections):\n",
        "\n",
        "        for detection_idx in range(len(detections)):\n",
        "\n",
        "            x1, y1, x2, y2 = detections.xyxy[detection_idx].astype(int)\n",
        "            cv2.rectangle(img = frame,pt1 = (x1, y1),pt2 = (x2, y2),color = (0, 255, 255),thickness= 2,)\n",
        "\n",
        "        return frame\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "kjNz1B_HUZTx"
      },
      "outputs": [],
      "source": [
        "def crowd_calculator(frame, detections, height, width):\n",
        "\n",
        "    in_car = 0\n",
        "    out_car = 0\n",
        "\n",
        "    for detection_idx in range(len(detections)):\n",
        "\n",
        "        x1, y1, x2, y2 = detections.xyxy[detection_idx].astype(int)\n",
        "\n",
        "        if y1 > height and x1 < width *1/2 :\n",
        "           in_car += 1\n",
        "\n",
        "        if y1< height  and x1 > width *1/2 :\n",
        "           out_car += 1\n",
        "\n",
        "\n",
        "        #make and plot the line counter\n",
        "    cv2.line(frame,(0, height), (width, height), (0,0, 255), 2)\n",
        "\n",
        "\n",
        "    cv2.putText(frame, f' in:{in_car}', (0,height -10), cv2.FONT_HERSHEY_SIMPLEX ,  1, (255,0,0), 2, cv2.LINE_AA)\n",
        "    cv2.putText(frame, f'out: {out_car}', (0, height + 30), cv2.FONT_ITALIC ,  1, (255,0,0), 2, cv2.LOCAL_OPTIM_SIGMA)\n",
        "\n",
        "    return frame"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_path = '/content/sample_video.mp4'\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "zUbQESuSt4r9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "ZuNPZ2hvHeZV",
        "outputId": "6fb525e6-4454-48b5-a69e-be6d83dc4833"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "local variable 'out_car' referenced before assignment",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-868e5be3a074>\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrowd_calculator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;31m# annotate and display frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0manotated_frame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbox_annotator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscene\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdetections\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-79-48b6b773ebce>\u001b[0m in \u001b[0;36mcrowd_calculator\u001b[0;34m(frame, detections, height, width)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m<\u001b[0m \u001b[0mheight\u001b[0m  \u001b[0;32mand\u001b[0m \u001b[0mx1\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m            \u001b[0mout_car\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'out_car' referenced before assignment"
          ]
        }
      ],
      "source": [
        "# create frame generator\n",
        "generator = sv.get_video_frames_generator(video_path)\n",
        "# create instance of BoxAnnotator\n",
        "box_annotator = sv.BoxAnnotator()\n",
        "# acquire first video frame\n",
        "iterator = iter(generator)\n",
        "frame = next(iterator)\n",
        "# model prediction on single frame and conversion to supervision Detections\n",
        "results = model(frame, verbose=False)[0]\n",
        "\n",
        "# convert to Detections\n",
        "detections = sv.Detections.from_ultralytics(results)\n",
        "# only consider class id from selected_classes define above\n",
        "detections = detections[np.isin(detections.class_id, selected_classes)]\n",
        "\n",
        "# format custom labels\n",
        "labels = [\n",
        "    f\"{CLASS_NAMES_DICT[class_id]} {confidence:0.2f}\"\n",
        "    for confidence, class_id in zip(detections.confidence, detections.class_id)\n",
        "\n",
        "\n",
        "]\n",
        "\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "# cap.set(cv2.CAP_PROP_POS_FRAMES, 200)  # Replace 50 with your desired frame number\n",
        "\n",
        "ret, frame = cap.read()\n",
        "\n",
        "height, width, channels = frame.shape\n",
        "\n",
        "height  = int(height-(height*1/3))\n",
        "width = int(width)\n",
        "\n",
        "\n",
        "\n",
        "frame = crowd_calculator(frame, detections, height, width)\n",
        "# annotate and display frame\n",
        "anotated_frame=box_annotator.annotate(scene=frame, detections=detections)\n",
        "\n",
        "%matplotlib inline\n",
        "sv.plot_image(anotated_frame, (16,16))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_path = '/content/sample_video.mp4'\n",
        "\n",
        "cap= cv2.VideoCapture(video_path)\n",
        "ret, frame = cap.read()\n",
        "\n",
        "height, width, channels = frame.shape\n",
        "print(frame.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7JM-8NKrOZC",
        "outputId": "03685270-79b0-42d9-fe56-79081b52a246"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(720, 1280, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f512VaV5q7dT",
        "outputId": "1990f226-ba27-4b26-a300-162b9600e119"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SupervisionWarnings: `track_buffer` in `ByteTrack.__init__` is deprecated and will be remove in `supervision-0.23.0`. Use 'lost_track_buffer' instead.\n",
            "SupervisionWarnings: `track_thresh` in `ByteTrack.__init__` is deprecated and will be remove in `supervision-0.23.0`. Use 'track_activation_threshold' instead.\n",
            "SupervisionWarnings: `match_thresh` in `ByteTrack.__init__` is deprecated and will be remove in `supervision-0.23.0`. Use 'minimum_matching_threshold' instead.\n"
          ]
        }
      ],
      "source": [
        "video_path = '/content/sample_video.mp4'\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "byte_tracker = sv.ByteTrack(track_thresh=0.25, track_buffer=30, match_thresh=0.8, frame_rate=30)\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Define the codec and create VideoWriter object\n",
        "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
        "out = cv2.VideoWriter('output.mp4', fourcc, 30.0, (1280,  720))\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    # Break the loop if the end of the video is reached\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    height, width, channels = frame.shape\n",
        "\n",
        "    results = model(frame, verbose = False)[0]\n",
        "\n",
        "    detections = sv.Detections.from_ultralytics(results)\n",
        "    detections = detections[np.isin(detections.class_id, selected_classes)]\n",
        "\n",
        "    detections = byte_tracker.update_with_detections(detections)\n",
        "    frame = box_anotator(frame, detections)\n",
        "\n",
        "\n",
        "    height  = int(height-(height*1/3))\n",
        "    width = int(width)\n",
        "\n",
        "    frame = crowd_calculator(frame, detections, height, width)\n",
        "\n",
        "    out.write(frame)\n",
        "\n",
        "# Release everything if job is finished\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class LineZone:\n",
        "  def __init__(self, start, end):\n",
        "    self.vector = np.array(end) - np.array(start)\n",
        "    self.in_count = 0\n",
        "    self.out_count = 0\n",
        "\n",
        "  def is_in_zone(self, point):\n",
        "    # Simplified calculation using cross product\n",
        "    return np.cross(self.vector, point - self.vector.start) > 0\n",
        "\n",
        "  def trigger(self, detections, tracker_id):\n",
        "    crossed_in = np.zeros(len(detections))\n",
        "    crossed_out = np.zeros(len(detections))\n",
        "    for i, detection in enumerate(detections):\n",
        "      if self.is_in_zone(detection[tracker_id]):\n",
        "        crossed_out[i] = 1\n",
        "      else:\n",
        "        crossed_in[i] = 1\n",
        "    self.in_count += crossed_in.sum()\n",
        "    self.out_count += crossed_out.sum()\n",
        "    return crossed_in, crossed_out\n"
      ],
      "metadata": {
        "id": "TMhwL84gf8Fi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = pd.DataFrame({\n",
        "    'Model': ['Linear Regression', 'Random Forest', 'Support Vector Machines','Desision Tree '],\n",
        "    'R-squared Score': [lin_r_squre*100, randome_forest*100, svr_r_squre*100, tree_r_squre*100]})\n",
        "models.sort_values(by='R-squared Score', ascending=False)"
      ],
      "metadata": {
        "id": "UucuVrxJu2xc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}